{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09b0dbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.types as tp\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77ff6ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('pavan_capstone_project').enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34ed2137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://g02.itversity.com:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pavan_capstone_project</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f5ee921cba8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b1ccd54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('use pavancs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7cbb9cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>database</th><th>tableName</th><th>isTemporary</th></tr>\n",
       "<tr><td>pavancs</td><td>details</td><td>false</td></tr>\n",
       "<tr><td>pavancs</td><td>status</td><td>false</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+---------+-----------+\n",
       "|database|tableName|isTemporary|\n",
       "+--------+---------+-----------+\n",
       "| pavancs|  details|      false|\n",
       "| pavancs|   status|      false|\n",
       "+--------+---------+-----------+"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('show tables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d9b7e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>studentsid</th><th>courseid</th><th>examdate</th><th>attendedstatus</th><th>marks</th><th>result</th></tr>\n",
       "<tr><td>S0023</td><td>C0023</td><td>28 Feb 19</td><td>Absent</td><td>0</td><td>Not Qualified</td></tr>\n",
       "<tr><td>S0022</td><td>C0022</td><td>27 Feb 19</td><td>Absent</td><td>0</td><td>Not Qualified</td></tr>\n",
       "<tr><td>S0021</td><td>C0021</td><td>20 Feb 19</td><td>Attended</td><td>90</td><td>Qualified</td></tr>\n",
       "<tr><td>S0020</td><td>C0020</td><td>19 Feb 19</td><td>Attended</td><td>90</td><td>Qualified</td></tr>\n",
       "<tr><td>S0017</td><td>C0017</td><td>5 Mar 19</td><td>Absent</td><td>0</td><td>Not Qualified</td></tr>\n",
       "<tr><td>S0016</td><td>C0016</td><td>4 Mar 19</td><td>Absent</td><td>0</td><td>Not Qualified</td></tr>\n",
       "<tr><td>S0015</td><td>C0015</td><td>3 Mar 19</td><td>Absent</td><td>0</td><td>Not Qualified</td></tr>\n",
       "<tr><td>S0014</td><td>C0014</td><td>2 Mar 19</td><td>Absent</td><td>0</td><td>Not Qualified</td></tr>\n",
       "<tr><td>S0011</td><td>C0011</td><td>27 Feb 19</td><td>Absent</td><td>0</td><td>Not Qualified</td></tr>\n",
       "<tr><td>S0010</td><td>C0010</td><td>26 Feb 19</td><td>Absent</td><td>0</td><td>Not Qualified</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------+--------+---------+--------------+-----+-------------+\n",
       "|studentsid|courseid| examdate|attendedstatus|marks|       result|\n",
       "+----------+--------+---------+--------------+-----+-------------+\n",
       "|     S0300|   C0010|26 Feb 19|        Absent|    0|Not Qualified|\n",
       "|     S0297|   C0007|23 Feb 19|        Absent|    0|Not Qualified|\n",
       "|     S0293|   C0027|15 Mar 19|      Attended|   77|    Qualified|\n",
       "|     S0290|   C0017| 5 Mar 19|        Absent|    0|Not Qualified|\n",
       "|     S0289|   C0016| 4 Mar 19|        Absent|    0|Not Qualified|\n",
       "|     S0288|   C0015| 3 Mar 19|        Absent|    0|Not Qualified|\n",
       "|     S0287|   C0014| 2 Mar 19|        Absent|    0|Not Qualified|\n",
       "|     S0284|   C0011|27 Feb 19|        Absent|    0|Not Qualified|\n",
       "|     S0283|   C0010|26 Feb 19|        Absent|    0|Not Qualified|\n",
       "|     S0280|   C0007|23 Feb 19|        Absent|    0|Not Qualified|\n",
       "+----------+--------+---------+--------------+-----+-------------+"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM pavancs.status LIMIT 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4657469f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfstatus = spark.sql(\"SELECT * FROM pavancs.status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd968a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * FROM pavancs.details LIMIT 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e3b0667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dfstatus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d9a002d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>result</th><th>count(1)</th></tr>\n",
       "<tr><td>Not Qualified</td><td>149</td></tr>\n",
       "<tr><td>Qualified</td><td>151</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------------+--------+\n",
       "|       result|count(1)|\n",
       "+-------------+--------+\n",
       "|Not Qualified|     149|\n",
       "|    Qualified|     151|\n",
       "+-------------+--------+"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('select distinct(result), count(*) from status group by result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41f29a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>count(1)</th></tr>\n",
       "<tr><td>149</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+\n",
       "|count(1)|\n",
       "+--------+\n",
       "|     149|\n",
       "+--------+"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select count(*) from status where attendedstatus = 'Absent'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "12187f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>max(marks)</th></tr>\n",
       "<tr><td>92</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------+\n",
       "|max(marks)|\n",
       "+----------+\n",
       "|        92|\n",
       "+----------+"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select max(marks) from status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c8ac107a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>min(marks)</th></tr>\n",
       "<tr><td>0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------+\n",
       "|min(marks)|\n",
       "+----------+\n",
       "|         0|\n",
       "+----------+"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select min(marks) from status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3b8723d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>avgmarks</th></tr>\n",
       "<tr><td>40.01</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+\n",
       "|avgmarks|\n",
       "+--------+\n",
       "|   40.01|\n",
       "+--------+"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select round(avg(marks),2) avgmarks from status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d802f91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f4c2aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdetails = spark.sql(\"SELECT * FROM pavancs.details\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "220341f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+----------+----------+\n",
      "|            courseid|title|          competency|complexity|coursetype|\n",
      "+--------------------+-----+--------------------+----------+----------+\n",
      "|               Cloud|C0004|BE (Hons) in CSE ...|    Domain|  Advanced|\n",
      "|               Cloud|C0005|BTech in Computer...|    Domain|  Advanced|\n",
      "|               Cloud|C0006|BTech in Computer...|    Domain|  Advanced|\n",
      "|               Cloud|C0007|BCA with Microsof...|  Security|  Advanced|\n",
      "|               Cloud|C0008|BTech in Informat...| Technical|  Advanced|\n",
      "|               Cloud|C0009|MCA with speciali...| Technical|  Advanced|\n",
      "|Hardware and Netw...|C0013|B.Sc in Hardware ...|    Domain|  Advanced|\n",
      "|Hardware and Netw...|C0017|M.Tech in Network...|    Domain|  Advanced|\n",
      "|Hardware and Netw...|C0018|M.Sc in Hardware ...|    Domain|  Advanced|\n",
      "|Hardware and Netw...|C0019|MSc in Wireless N...|    Domain|  Advanced|\n",
      "|Hardware and Netw...|C0020|Diploma in Comput...|    Domain|  Advanced|\n",
      "|Hardware and Netw...|C0021|Diploma of Networ...|    Domain|  Advanced|\n",
      "|Hardware and Netw...|C0022|Diploma in Comput...|    Domain|  Advanced|\n",
      "|Hardware and Netw...|C0023|Diploma in IT and...| Technical|  Advanced|\n",
      "|     Web Development|C0025|Graduate Certific...|    Domain|  Advanced|\n",
      "|     Web Development|C0029|Diploma in Contem...| Technical|  Advanced|\n",
      "|               Cloud|C0001|Certificate in Cl...| Technical|     Basic|\n",
      "|               Cloud|C0002|Certificate in Vi...| Technical|     Basic|\n",
      "|               Cloud|C0010|ME in Cloud Compu...| Technical|     Basic|\n",
      "|               Cloud|C0011|MTech Computer Sc...| Technical|     Basic|\n",
      "+--------------------+-----+--------------------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfdetails.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec69dbe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+---------+--------------+-----+---------+\n",
      "|studentsid|courseid| examdate|attendedstatus|marks|   result|\n",
      "+----------+--------+---------+--------------+-----+---------+\n",
      "|     S0299|   C0009|25 Feb 19|      Attended|   91|Qualified|\n",
      "|     S0295|   C0029|19 Feb 19|      Attended|   87|Qualified|\n",
      "|     S0282|   C0009|25 Feb 19|      Attended|   91|Qualified|\n",
      "|     S0267|   C0009|25 Feb 19|      Attended|   91|Qualified|\n",
      "|     S0251|   C0009|25 Feb 19|      Attended|   91|Qualified|\n",
      "|     S0236|   C0009|25 Feb 19|      Attended|   91|Qualified|\n",
      "|     S0216|   C0009|25 Feb 19|      Attended|   91|Qualified|\n",
      "|     S0200|   C0009|25 Feb 19|      Attended|   91|Qualified|\n",
      "|     S0180|   C0009|25 Feb 19|      Attended|   91|Qualified|\n",
      "|     S0169|   C0009|25 Feb 19|      Attended|   91|Qualified|\n",
      "|     S0165|   C0029|19 Feb 19|      Attended|   87|Qualified|\n",
      "|     S0150|   C0009|25 Feb 19|      Attended|   91|Qualified|\n",
      "|     S0128|   C0009|25 Feb 19|      Attended|   91|Qualified|\n",
      "|     S0106|   C0009|25 Feb 19|      Attended|   91|Qualified|\n",
      "|     S0094|   C0029|19 Feb 19|      Attended|   87|Qualified|\n",
      "|     S0078|   C0009|25 Feb 19|      Attended|   91|Qualified|\n",
      "|     S0076|   C0009|25 Feb 19|      Attended|   91|Qualified|\n",
      "|     S0072|   C0029|19 Feb 19|      Attended|   87|Qualified|\n",
      "|     S0057|   C0009|25 Feb 19|      Attended|   91|Qualified|\n",
      "|     S0055|   C0009|25 Feb 19|      Attended|   91|Qualified|\n",
      "+----------+--------+---------+--------------+-----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfstatus.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f99a14c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>Min_Marks</th><th>Max_Marks</th><th>Average_Marks</th></tr>\n",
       "<tr><td>0</td><td>92</td><td>40.01</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------+---------+-------------+\n",
       "|Min_Marks|Max_Marks|Average_Marks|\n",
       "+---------+---------+-------------+\n",
       "|        0|       92|        40.01|\n",
       "+---------+---------+-------------+"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"SELECT min(marks) as Min_Marks, max(marks) as Max_Marks, round(avg(marks),2) as Average_Marks from status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c116a397",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
